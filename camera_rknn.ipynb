{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896b9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from rknnlite.api import RKNNLite"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee810774",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "!v4l2-ctl -d /dev/video0 --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50dbc529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "MODEL_PATH = \"./model/yolo11n_rk3588.rknn\"\n",
    "CAMERA_INDEX = 0\n",
    "INPUT_SIZE = (640, 640)\n",
    "CONF_THRESHOLD = 0.25\n",
    "NMS_THRESHOLD = 0.45\n",
    "\n",
    "# YOLO기본 클래스\n",
    "CLASSES = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "           'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "           'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "           'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "           'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "           'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "           'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "           'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "           'hair drier', 'toothbrush']\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad443cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(outputs, conf_threshold, nms_threshold):\n",
    "    # YOLOv11[1, 84, 8400](class: 80, box: 4) -> (84, 8400)\n",
    "    predictions = np.squeeze(outputs[0]).T\n",
    "\n",
    "    # boxes = []\n",
    "    # confidences = []\n",
    "    # class_ids = []\n",
    "\n",
    "    # 점수, 클래스 추출\n",
    "    scores = predictions[:, 4:]\n",
    "    max_scores = np.max(scores, axis=1)\n",
    "    class_ids = np.argmax(scores, axis=1)\n",
    "\n",
    "    # 필터\n",
    "    mask = (max_scores > conf_threshold) & (class_ids == 0)\n",
    "\n",
    "    preds = predictions[mask]\n",
    "    scores = max_scores[mask]\n",
    "    class_ids = class_ids[mask]\n",
    "\n",
    "    if len(preds) == 0:\n",
    "        return [], [], []\n",
    "    \n",
    "    # 필터링된 박스좌표(cx, cy, w, h -> x, y, w, h)\n",
    "    w = preds[:, 2]\n",
    "    h = preds[:, 3]\n",
    "    x = preds[:, 0] - w/2\n",
    "    y = preds[:, 1] - h/2\n",
    "\n",
    "    # NMSbox\n",
    "    boxes = np.stack((x, y, w, h), axis=1).tolist()\n",
    "    confidences = scores.tolist()\n",
    "\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "    person_boxs = []\n",
    "    person_scores = []\n",
    "    person_cls_ids = []\n",
    "\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            person_boxs.append(boxes[i])\n",
    "            person_scores.append(confidences[i])\n",
    "            person_cls_ids.append(class_ids[i])\n",
    "\n",
    "    return person_boxs, person_scores, person_cls_ids\n",
    "\n",
    "\n",
    "    # for i in range(predictions.shape[0]):\n",
    "    #     row = predictions[i]\n",
    "    #     scores = row[4:] # 80개 클래스 확률\n",
    "    #     class_id = np.argmax(scores)\n",
    "    #     confidence = scores[class_id]\n",
    "\n",
    "    #     if confidence > conf_threshold:\n",
    "    #         # Cx, Cy, W, H -> X1, Y1, W, H (NMSBoxes용)\n",
    "    #         w = row[2]\n",
    "    #         h = row[3]\n",
    "    #         x = row[0] - w / 2\n",
    "    #         y = row[1] - h / 2\n",
    "            \n",
    "    #         boxes.append([x, y, w, h])\n",
    "    #         confidences.append(float(confidence))\n",
    "    #         class_ids.append(class_id)\n",
    "\n",
    "    # # NMS 적용\n",
    "    # indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "    \n",
    "    # final_boxes = []\n",
    "    # final_scores = []\n",
    "    # final_cls_ids = []\n",
    "\n",
    "    # if len(indices) > 0:\n",
    "    #     for i in indices.flatten():\n",
    "    #         final_boxes.append(boxes[i])\n",
    "    #         final_scores.append(confidences[i])\n",
    "    #         final_cls_ids.append(class_ids[i])\n",
    "\n",
    "    # return final_boxes, final_scores, final_cls_ids\n",
    "\n",
    "# 추론\n",
    "def detect_object():\n",
    "    rknn_lite = RKNNLite()\n",
    "\n",
    "    print(f\"Loading model: {MODEL_PATH}\")\n",
    "    if rknn_lite.load_rknn(MODEL_PATH) != 0:\n",
    "        print(\"Model load fail\")\n",
    "        return\n",
    "\n",
    "    print(\"Init runtime\")\n",
    "    if rknn_lite.init_runtime() != 0:\n",
    "        print(\"Init runtime fail\")\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    # 타이머\n",
    "    tm = cv2.TickMeter()\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Camera not found\")\n",
    "        return\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    print(f\"{int(width)}x{int(height)}\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        tm.start()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # 왼쪽 카메라만 사용\n",
    "        h, w = frame.shape[:2]\n",
    "        half_w = w // 2\n",
    "        left_camera = frame[0:h, half_w:w]\n",
    "        frame = left_camera\n",
    "\n",
    "        # 전처리\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, INPUT_SIZE)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "        # 추론\n",
    "        outputs = rknn_lite.inference(inputs=[img])\n",
    "\n",
    "        # 후처리\n",
    "        boxes, scores, class_ids = post_process(outputs, CONF_THRESHOLD, NMS_THRESHOLD)\n",
    "\n",
    "        tm.stop()\n",
    "        fps = tm.getFPS()\n",
    "\n",
    "        # 화면 출력\n",
    "        scale_x, scale_y = frame.shape[1] / INPUT_SIZE[0], frame.shape[0] / INPUT_SIZE[1]\n",
    "        for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "            x, y, w, h = box\n",
    "            x1, y1 = int(x * scale_x), int(y * scale_y)\n",
    "            x2, y2 = int((x + w) * scale_x), int((y + h) * scale_y)\n",
    "\n",
    "            color = COLORS[class_id]\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, f'{CLASSES[class_id]} {score:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        cv2.putText(frame, f\"FPS: {round(fps)}\", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"OrangePi 5 Plus with YOLO11n model Person Detection\", frame)\n",
    "\n",
    "        tm.reset()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    rknn_lite.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc5b337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo-s-test/.conda/envs/qt/lib/python3.10/site-packages/rknnlite/api/rknn_lite.py:41: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "W rknn-toolkit-lite2 version: 2.3.0\n",
      "W Query dynamic range failed. Ret code: RKNN_ERR_MODEL_INVALID. (If it is a static shape RKNN model, please ignore the above warning message.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: ./model/yolo11n_rk3588.rknn\n",
      "Init runtime\n",
      "I RKNN: [15:08:30.155] RKNN Runtime Information, librknnrt version: 1.6.0 (9a7b5d24c@2023-12-13T17:31:11)\n",
      "I RKNN: [15:08:30.155] RKNN Driver Information, version: 0.9.6\n",
      "I RKNN: [15:08:30.155] RKNN Model Information, version: 6, toolkit version: 2.3.0(compiler version: 2.3.0 (c949ad889d@2024-11-07T11:39:30)), target: RKNPU v2, target platform: rk3588, framework name: ONNX, framework layout: NCHW, model inference type: static_shape\n",
      "W RKNN: [15:08:30.155] RKNN Model version: 2.3.0 not match with rknn runtime version: 1.6.0\n",
      "W RKNN: [15:08:30.184] query RKNN_QUERY_INPUT_DYNAMIC_RANGE error, rknn model is static shape type, please export rknn with dynamic_shapes\n",
      "1280x480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "detect_object()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
